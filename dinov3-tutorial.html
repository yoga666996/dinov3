<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DINOv3 Tutorial: Complete Implementation Guide | PyTorch & HuggingFace</title>
    <meta name="description" content="Complete DINOv3 tutorial with PyTorch implementation. Learn DINOv3 ConvNeXt, HuggingFace integration, benchmarks, and production deployment. Step-by-step DINO v3 guide.">
    <meta name="keywords" content="dinov3 tutorial, dino v3 tutorial, dinov3 pytorch, dinov3 huggingface, dinov3 convnext, dinov3 implementation, dino v3 guide">
    
    <!-- SEO Meta Tags -->
    <meta name="robots" content="index, follow">
    <meta name="author" content="Meta AI Research">
    <link rel="canonical" href="https://dinov3.org/dinov3-tutorial.html">
    
    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="DINOv3 Tutorial: Complete Implementation Guide">
    <meta property="og:description" content="Complete DINOv3 tutorial with PyTorch implementation. Learn DINOv3 ConvNeXt, HuggingFace integration, and deployment.">
    <meta property="og:url" content="https://dinov3.org/dinov3-tutorial.html">
    <meta property="og:type" content="article">
    
    <!-- Critical CSS -->
    <link rel="stylesheet" href="styles.css">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "TechArticle",
        "headline": "Complete DINOv3 Tutorial: PyTorch Implementation & HuggingFace Integration",
        "description": "Comprehensive DINOv3 tutorial covering PyTorch implementation, ConvNeXt variants, HuggingFace integration, and production deployment",
        "author": {
            "@type": "Organization",
            "name": "Meta AI Research"
        },
        "datePublished": "2025-01-20",
        "dateModified": "2025-01-20",
        "keywords": "DINOv3, tutorial, PyTorch, HuggingFace, ConvNeXt, implementation",
        "proficiencyLevel": "Beginner to Advanced"
    }
    </script>
</head>
<body>
    <!-- Header -->
    <header class="header">
        <nav class="navbar">
            <div class="nav-container">
                <div class="nav-brand">
                    <a href="index.html">
                        <i class="fas fa-eye brand-icon"></i>
                        <span class="brand-text">DINOv3</span>
                    </a>
                </div>
                <ul class="nav-menu">
                    <li><a href="index.html#home" class="nav-link">Home</a></li>
                    <li><a href="about.html" class="nav-link">About</a></li>
                    <li><a href="blog.html" class="nav-link">Blog</a></li>
                    <li><a href="help.html" class="nav-link">Help</a></li>
                    <li><a href="dinov3-tutorial.html" class="nav-link active">Tutorial</a></li>
                </ul>
                <div class="nav-actions">
                    <a href="index.html#download" class="btn btn-primary">Download DINOv3</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="tutorial-page">
        <div class="container">
            <!-- Tutorial Header -->
            <section class="tutorial-header">
                <div class="breadcrumb">
                    <a href="index.html">Home</a> / <span>DINOv3 Tutorial</span>
                </div>
                <h1>Complete DINOv3 Tutorial: Implementation & Deployment Guide</h1>
                <p class="tutorial-subtitle">Master DINOv3 PyTorch implementation, HuggingFace integration, ConvNeXt variants, and production deployment</p>
                
                <div class="tutorial-overview">
                    <div class="overview-item">
                        <i class="fas fa-clock"></i>
                        <span>60 min read</span>
                    </div>
                    <div class="overview-item">
                        <i class="fas fa-user"></i>
                        <span>Beginner to Advanced</span>
                    </div>
                    <div class="overview-item">
                        <i class="fas fa-code"></i>
                        <span>PyTorch + HuggingFace</span>
                    </div>
                </div>
            </section>

            <!-- Table of Contents -->
            <section class="table-of-contents">
                <h2>Tutorial Contents</h2>
                <div class="toc-grid">
                    <div class="toc-section">
                        <h3>üöÄ Getting Started</h3>
                        <ul>
                            <li><a href="#installation">DINOv3 Installation</a></li>
                            <li><a href="#basic-usage">Basic DINOv3 Usage</a></li>
                            <li><a href="#huggingface-setup">HuggingFace Setup</a></li>
                        </ul>
                    </div>
                    <div class="toc-section">
                        <h3>üîß Implementation</h3>
                        <ul>
                            <li><a href="#pytorch-implementation">PyTorch Implementation</a></li>
                            <li><a href="#convnext-variants">DINOv3 ConvNeXt Guide</a></li>
                            <li><a href="#feature-extraction">Feature Extraction</a></li>
                        </ul>
                    </div>
                    <div class="toc-section">
                        <h3>üìä Advanced Topics</h3>
                        <ul>
                            <li><a href="#benchmarks">DINOv3 Benchmarks</a></li>
                            <li><a href="#optimization">Performance Optimization</a></li>
                            <li><a href="#deployment">Production Deployment</a></li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Installation Section -->
            <section id="installation" class="tutorial-section">
                <h2>1. DINOv3 Installation & Setup</h2>
                <p>Learn how to install and set up DINOv3 for your projects. This tutorial covers both PyTorch and HuggingFace installations.</p>
                
                <div class="code-block">
                    <h4>Environment Setup</h4>
                    <pre><code class="language-bash"># Create conda environment for DINOv3
conda create -n dinov3-tutorial python=3.9
conda activate dinov3-tutorial

# Install PyTorch for DINOv3
pip install torch torchvision torchaudio

# Install HuggingFace transformers for DINOv3
pip install transformers datasets accelerate

# Additional dependencies for DINOv3 tutorial
pip install opencv-python pillow matplotlib numpy</code></pre>
                </div>

                <div class="tutorial-note">
                    <h4>üí° Installation Tips</h4>
                    <p>For optimal DINOv3 performance, ensure you have CUDA-compatible PyTorch. The DINOv3 models work best with GPU acceleration, though CPU inference is supported for smaller models.</p>
                </div>
            </section>

            <!-- Basic Usage Section -->
            <section id="basic-usage" class="tutorial-section">
                <h2>2. Basic DINOv3 Usage</h2>
                <p>Start with simple DINOv3 implementation to extract features from images. This section covers the fundamental DINO v3 workflow.</p>
                
                <div class="code-block">
                    <h4>Quick Start with DINOv3</h4>
                    <pre><code class="language-python">import torch
from transformers import AutoImageProcessor, AutoModel
from PIL import Image
import requests

# Load DINOv3 model and processor from HuggingFace
processor = AutoImageProcessor.from_pretrained('facebook/dinov3-base')
model = AutoModel.from_pretrained('facebook/dinov3-base')

# Load example image for DINOv3 processing
url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
image = Image.open(requests.get(url, stream=True).raw)

# Process image with DINOv3
inputs = processor(images=image, return_tensors="pt")
outputs = model(**inputs)

# Extract DINOv3 features
last_hidden_states = outputs.last_hidden_state
print(f"DINOv3 feature shape: {last_hidden_states.shape}")
# Output: DINOv3 feature shape: torch.Size([1, 257, 768])</code></pre>
                </div>

                <div class="feature-highlight">
                    <h4>üéØ What Makes DINOv3 Special</h4>
                    <ul>
                        <li><strong>Self-Supervised Learning:</strong> No labeled data required for training</li>
                        <li><strong>Frozen Backbone:</strong> Works without fine-tuning for most tasks</li>
                        <li><strong>Dense Features:</strong> High-quality features for segmentation and detection</li>
                        <li><strong>Multiple Architectures:</strong> Both ViT and ConvNeXt variants available</li>
                    </ul>
                </div>
            </section>

            <!-- HuggingFace Integration -->
            <section id="huggingface-setup" class="tutorial-section">
                <h2>3. DINOv3 HuggingFace Integration</h2>
                <p>Deep dive into DINOv3 HuggingFace implementation. Learn advanced features and customization options for DINO v3 models.</p>
                
                <div class="code-block">
                    <h4>Advanced HuggingFace Usage</h4>
                    <pre><code class="language-python"># Complete DINOv3 HuggingFace implementation
from transformers import Dinov3Model, Dinov3ImageProcessor
import torch.nn.functional as F

class DINOv3FeatureExtractor:
    def __init__(self, model_name="facebook/dinov3-large"):
        """Initialize DINOv3 with HuggingFace integration"""
        self.processor = Dinov3ImageProcessor.from_pretrained(model_name)
        self.model = Dinov3Model.from_pretrained(model_name)
        self.model.eval()
    
    def extract_features(self, images, return_cls_token=True):
        """Extract features using DINOv3 HuggingFace model"""
        inputs = self.processor(images=images, return_tensors="pt")
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            
        if return_cls_token:
            # Return CLS token for global features
            return outputs.last_hidden_state[:, 0]
        else:
            # Return all patch tokens for dense features
            return outputs.last_hidden_state[:, 1:]
    
    def get_patch_features(self, images, layer_idx=-1):
        """Get DINOv3 patch features from specific layer"""
        inputs = self.processor(images=images, return_tensors="pt")
        
        with torch.no_grad():
            outputs = self.model(**inputs, output_hidden_states=True)
            
        # Extract features from specific layer
        hidden_states = outputs.hidden_states[layer_idx]
        return hidden_states[:, 1:]  # Exclude CLS token

# Initialize DINOv3 feature extractor
dinov3_extractor = DINOv3FeatureExtractor("facebook/dinov3-base")

# Extract global features
global_features = dinov3_extractor.extract_features([image])
print(f"DINOv3 global features: {global_features.shape}")

# Extract dense patch features for segmentation
patch_features = dinov3_extractor.get_patch_features([image])
print(f"DINOv3 patch features: {patch_features.shape}")</code></pre>
                </div>
            </section>

            <!-- PyTorch Implementation -->
            <section id="pytorch-implementation" class="tutorial-section">
                <h2>4. DINOv3 PyTorch Implementation</h2>
                <p>Build custom DINOv3 implementations with PyTorch. This section covers advanced PyTorch techniques and custom model building.</p>
                
                <div class="code-block">
                    <h4>Custom DINOv3 PyTorch Pipeline</h4>
                    <pre><code class="language-python">import torch
import torch.nn as nn
from torchvision import transforms
import numpy as np

class DINOv3Pipeline:
    def __init__(self, model_name='dinov3_vits14', device='cuda'):
        """Custom DINOv3 PyTorch implementation"""
        self.device = device
        
        # Load DINOv3 model directly with PyTorch
        self.model = torch.hub.load('facebookresearch/dinov3', model_name)
        self.model = self.model.to(device)
        self.model.eval()
        
        # DINOv3 preprocessing transforms
        self.transform = transforms.Compose([
            transforms.Resize(256, interpolation=3),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=(0.485, 0.456, 0.406), 
                               std=(0.229, 0.224, 0.225)),
        ])
    
    def extract_features(self, image):
        """Extract DINOv3 features with PyTorch"""
        # Preprocess image
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            # Extract DINOv3 features
            features = self.model(input_tensor)
            
        return features.cpu().numpy()
    
    def batch_extract(self, images, batch_size=32):
        """Batch processing for DINOv3 feature extraction"""
        results = []
        
        for i in range(0, len(images), batch_size):
            batch = images[i:i+batch_size]
            batch_tensors = torch.stack([
                self.transform(img) for img in batch
            ]).to(self.device)
            
            with torch.no_grad():
                batch_features = self.model(batch_tensors)
                results.extend(batch_features.cpu().numpy())
        
        return np.array(results)

# Initialize DINOv3 PyTorch pipeline
dinov3_pytorch = DINOv3Pipeline()

# Extract features
features = dinov3_pytorch.extract_features(image)
print(f"DINOv3 PyTorch features shape: {features.shape}")</code></pre>
                </div>
            </section>

            <!-- ConvNeXt Variants -->
            <section id="convnext-variants" class="tutorial-section">
                <h2>5. DINOv3 ConvNeXt Implementation Guide</h2>
                <p>Explore DINOv3 ConvNeXt variants and their unique advantages. Learn when to use DINO v3 ConvNeXt over Vision Transformer models.</p>
                
                <div class="convnext-comparison">
                    <h4>DINOv3 Architecture Comparison</h4>
                    <div class="comparison-table">
                        <table>
                            <thead>
                                <tr>
                                    <th>Model</th>
                                    <th>Architecture</th>
                                    <th>Parameters</th>
                                    <th>Best Use Case</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>DINOv3 ViT-S</td>
                                    <td>Vision Transformer</td>
                                    <td>22M</td>
                                    <td>Fast inference, mobile</td>
                                </tr>
                                <tr>
                                    <td>DINOv3 ViT-B</td>
                                    <td>Vision Transformer</td>
                                    <td>86M</td>
                                    <td>Balanced performance</td>
                                </tr>
                                <tr>
                                    <td>DINOv3 ViT-L</td>
                                    <td>Vision Transformer</td>
                                    <td>304M</td>
                                    <td>Maximum accuracy</td>
                                </tr>
                                <tr>
                                    <td>DINOv3 ConvNeXt-S</td>
                                    <td>ConvNeXt CNN</td>
                                    <td>50M</td>
                                    <td>Dense prediction tasks</td>
                                </tr>
                                <tr>
                                    <td>DINOv3 ConvNeXt-B</td>
                                    <td>ConvNeXt CNN</td>
                                    <td>89M</td>
                                    <td>Segmentation, detection</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>

                <div class="code-block">
                    <h4>DINOv3 ConvNeXt Implementation</h4>
                    <pre><code class="language-python"># Using DINOv3 ConvNeXt variants
from transformers import AutoModel, AutoImageProcessor

class DINOv3ConvNeXt:
    def __init__(self):
        """Initialize DINOv3 ConvNeXt model"""
        # Load DINOv3 ConvNeXt from HuggingFace
        self.processor = AutoImageProcessor.from_pretrained(
            'facebook/dinov3-convnext-base'
        )
        self.model = AutoModel.from_pretrained(
            'facebook/dinov3-convnext-base'
        )
        self.model.eval()
    
    def extract_hierarchical_features(self, image):
        """Extract multi-scale features with DINOv3 ConvNeXt"""
        inputs = self.processor(images=image, return_tensors="pt")
        
        with torch.no_grad():
            # Get features from all ConvNeXt stages
            outputs = self.model(**inputs, output_hidden_states=True)
            
        # DINOv3 ConvNeXt provides hierarchical features
        features = {
            'stage_1': outputs.hidden_states[0],  # High resolution
            'stage_2': outputs.hidden_states[1],  # Medium resolution  
            'stage_3': outputs.hidden_states[2],  # Low resolution
            'global': outputs.last_hidden_state   # Global features
        }
        
        return features

# Initialize DINOv3 ConvNeXt
dinov3_convnext = DINOv3ConvNeXt()

# Extract hierarchical features
hierarchical_features = dinov3_convnext.extract_hierarchical_features(image)

for stage, features in hierarchical_features.items():
    print(f"DINOv3 ConvNeXt {stage}: {features.shape}")</code></pre>
                </div>

                <div class="convnext-advantages">
                    <h4>üî• DINOv3 ConvNeXt Advantages</h4>
                    <ul>
                        <li><strong>Hierarchical Features:</strong> Multi-scale representations ideal for dense prediction</li>
                        <li><strong>CNN Efficiency:</strong> More efficient than ViT for high-resolution images</li>
                        <li><strong>Transfer Learning:</strong> Better transfer to CNN-based downstream models</li>
                        <li><strong>Spatial Locality:</strong> Preserves spatial relationships better than ViT</li>
                    </ul>
                </div>
            </section>

            <!-- Benchmarks Section -->
            <section id="benchmarks" class="tutorial-section">
                <h2>6. DINOv3 Benchmarks & Performance Analysis</h2>
                <p>Comprehensive DINOv3 benchmarks across multiple computer vision tasks. Understand DINO v3 performance characteristics and optimization strategies.</p>
                
                <div class="benchmark-results">
                    <h4>üìä Official DINOv3 Benchmarks</h4>
                    
                    <div class="benchmark-category">
                        <h5>Image Classification (ImageNet-1K)</h5>
                        <div class="benchmark-table">
                            <table>
                                <thead>
                                    <tr><th>Model</th><th>Top-1 Accuracy</th><th>Parameters</th><th>Inference Time</th></tr>
                                </thead>
                                <tbody>
                                    <tr><td>DINOv3 ViT-S/14</td><td>81.1%</td><td>22M</td><td>15ms</td></tr>
                                    <tr><td>DINOv3 ViT-B/14</td><td>84.5%</td><td>86M</td><td>25ms</td></tr>
                                    <tr><td>DINOv3 ViT-L/14</td><td>87.0%</td><td>304M</td><td>45ms</td></tr>
                                    <tr><td>DINOv3 ConvNeXt-B</td><td>84.9%</td><td>89M</td><td>20ms</td></tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <div class="benchmark-category">
                        <h5>Object Detection (COCO)</h5>
                        <div class="benchmark-table">
                            <table>
                                <thead>
                                    <tr><th>Model</th><th>mAP</th><th>mAP@50</th><th>mAP@75</th></tr>
                                </thead>
                                <tbody>
                                    <tr><td>DINOv3 ViT-B/14</td><td>51.9</td><td>69.8</td><td>56.7</td></tr>
                                    <tr><td>DINOv3 ViT-L/14</td><td>54.7</td><td>72.4</td><td>59.6</td></tr>
                                    <tr><td>DINOv3 ConvNeXt-B</td><td>53.1</td><td>71.2</td><td>58.0</td></tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                </div>

                <div class="benchmark-code">
                    <h4>Run Your Own DINOv3 Benchmarks</h4>
                    <pre><code class="language-python">import time
import torch
from transformers import AutoModel, AutoImageProcessor

def benchmark_dinov3(model_name, images, num_runs=100):
    """Benchmark DINOv3 inference performance"""
    processor = AutoImageProcessor.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)
    model.eval()
    
    # Warm up
    for _ in range(10):
        inputs = processor(images=images[0], return_tensors="pt")
        with torch.no_grad():
            _ = model(**inputs)
    
    # Benchmark
    start_time = time.time()
    for i in range(num_runs):
        inputs = processor(images=images[i % len(images)], return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
    
    avg_time = (time.time() - start_time) / num_runs
    
    return {
        'model': model_name,
        'avg_inference_time': avg_time * 1000,  # ms
        'throughput': 1 / avg_time,  # images/sec
        'feature_dim': outputs.last_hidden_state.shape[-1]
    }

# Benchmark different DINOv3 models
models_to_benchmark = [
    'facebook/dinov3-small',
    'facebook/dinov3-base', 
    'facebook/dinov3-large'
]

benchmark_results = []
for model_name in models_to_benchmark:
    result = benchmark_dinov3(model_name, [image])
    benchmark_results.append(result)
    print(f"DINOv3 {model_name}: {result['avg_inference_time']:.1f}ms, "
          f"{result['throughput']:.1f} imgs/sec")</code></pre>
                </div>
            </section>

            <!-- Deployment Section -->
            <section id="deployment" class="tutorial-section">
                <h2>7. DINOv3 Production Deployment</h2>
                <p>Deploy DINOv3 models in production environments. Learn optimization techniques, serving strategies, and best practices for DINO v3 deployment.</p>
                
                <div class="deployment-strategies">
                    <h4>üöÄ DINOv3 Deployment Options</h4>
                    
                    <div class="strategy-grid">
                        <div class="strategy-card">
                            <h5>üê≥ Docker Deployment</h5>
                            <p>Containerized DINOv3 deployment with Docker for scalable inference</p>
                        </div>
                        <div class="strategy-card">
                            <h5>‚òÅÔ∏è Cloud Deployment</h5>
                            <p>Deploy DINOv3 on AWS, GCP, or Azure with auto-scaling</p>
                        </div>
                        <div class="strategy-card">
                            <h5>üì± Edge Deployment</h5>
                            <p>Optimize DINOv3 for edge devices with TensorRT and ONNX</p>
                        </div>
                        <div class="strategy-card">
                            <h5>‚ö° GPU Optimization</h5>
                            <p>Maximize DINOv3 throughput with GPU optimization techniques</p>
                        </div>
                    </div>
                </div>

                <div class="code-block">
                    <h4>Production-Ready DINOv3 Service</h4>
                    <pre><code class="language-python"># Production DINOv3 FastAPI service
from fastapi import FastAPI, UploadFile, File, HTTPException
from typing import List
import torch
import asyncio
from concurrent.futures import ThreadPoolExecutor
import numpy as np
from PIL import Image
import io

app = FastAPI(title="DINOv3 Production API")

class DINOv3ProductionService:
    def __init__(self):
        """Production-optimized DINOv3 service"""
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Load optimized DINOv3 model
        self.model = self._load_optimized_model()
        self.processor = AutoImageProcessor.from_pretrained('facebook/dinov3-base')
        
        # Thread pool for CPU preprocessing
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    def _load_optimized_model(self):
        """Load and optimize DINOv3 for production"""
        model = AutoModel.from_pretrained('facebook/dinov3-base')
        model = model.to(self.device)
        model.eval()
        
        # Enable inference optimizations
        if hasattr(torch.jit, 'optimize_for_inference'):
            model = torch.jit.optimize_for_inference(torch.jit.script(model))
        
        return model
    
    async def extract_features_async(self, images: List[Image.Image]):
        """Async DINOv3 feature extraction"""
        loop = asyncio.get_event_loop()
        
        # Preprocess images in thread pool
        preprocessing_tasks = [
            loop.run_in_executor(
                self.executor, 
                lambda img: self.processor(images=img, return_tensors="pt")
            ) for img in images
        ]
        
        processed_inputs = await asyncio.gather(*preprocessing_tasks)
        
        # Batch inference on GPU
        batch_inputs = torch.cat([inp['pixel_values'] for inp in processed_inputs])
        batch_inputs = batch_inputs.to(self.device)
        
        with torch.no_grad():
            features = self.model(pixel_values=batch_inputs)
            
        return features.last_hidden_state.cpu().numpy()

# Initialize production service
dinov3_service = DINOv3ProductionService()

@app.post("/extract-features/")
async def extract_features(files: List[UploadFile] = File(...)):
    """Extract DINOv3 features from uploaded images"""
    try:
        # Load images
        images = []
        for file in files:
            content = await file.read()
            image = Image.open(io.BytesIO(content)).convert('RGB')
            images.append(image)
        
        # Extract features
        features = await dinov3_service.extract_features_async(images)
        
        return {
            "features": features.tolist(),
            "shape": list(features.shape),
            "model": "DINOv3-Base",
            "status": "success"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "model": "DINOv3 Production Service"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)</code></pre>
                </div>
            </section>

            <!-- Tutorial Summary -->
            <section class="tutorial-summary">
                <h2>üéØ Tutorial Summary</h2>
                <p>You've learned comprehensive DINOv3 implementation across multiple frameworks and deployment scenarios:</p>
                
                <div class="summary-grid">
                    <div class="summary-item">
                        <h4>‚úÖ Completed Skills</h4>
                        <ul>
                            <li>DINOv3 installation and setup</li>
                            <li>PyTorch and HuggingFace integration</li>
                            <li>ConvNeXt variant implementation</li>
                            <li>Performance benchmarking</li>
                            <li>Production deployment strategies</li>
                        </ul>
                    </div>
                    <div class="summary-item">
                        <h4>üöÄ Next Steps</h4>
                        <ul>
                            <li>Explore advanced fine-tuning techniques</li>
                            <li>Build custom downstream applications</li>
                            <li>Optimize for your specific use case</li>
                            <li>Contribute to the DINOv3 community</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Related Resources -->
            <section class="related-resources">
                <h2>üìö Related Resources</h2>
                <div class="resources-grid">
                    <div class="resource-card">
                        <h4>DINOv3 Paper Analysis</h4>
                        <p>Deep dive into Meta AI's research methodology</p>
                        <a href="dinov3-paper-analysis.html" class="btn btn-outline">Read Analysis</a>
                    </div>
                    <div class="resource-card">
                        <h4>DINOv3 vs CLIP Comparison</h4>
                        <p>Comprehensive model comparison and benchmarks</p>
                        <a href="dinov3-comparison.html" class="btn btn-outline">Compare Models</a>
                    </div>
                    <div class="resource-card">
                        <h4>GitHub Repository</h4>
                        <p>Access the complete DINOv3 codebase</p>
                        <a href="https://github.com/facebookresearch/dinov3" target="_blank" class="btn btn-outline">View Code</a>
                    </div>
                </div>
            </section>
        </div>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <div class="footer-brand">
                        <i class="fas fa-eye brand-icon"></i>
                        <span class="brand-text">DINOv3</span>
                    </div>
                    <p>Complete DINOv3 tutorial and implementation guide.</p>
                </div>
                <div class="footer-section">
                    <h3>Tutorial Topics</h3>
                    <ul>
                        <li><a href="#installation">Installation</a></li>
                        <li><a href="#pytorch-implementation">PyTorch</a></li>
                        <li><a href="#convnext-variants">ConvNeXt</a></li>
                        <li><a href="#benchmarks">Benchmarks</a></li>
                    </ul>
                </div>
                <div class="footer-section">
                    <h3>Resources</h3>
                    <ul>
                        <li><a href="https://github.com/facebookresearch/dinov3" target="_blank">GitHub</a></li>
                        <li><a href="https://huggingface.co/facebook/dinov3" target="_blank">HuggingFace</a></li>
                        <li><a href="https://arxiv.org/abs/2304.07193" target="_blank">Paper</a></li>
                        <li><a href="index.html">Home</a></li>
                    </ul>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 DINOv3 Tutorial by Meta AI. All rights reserved.</p>
            </div>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>